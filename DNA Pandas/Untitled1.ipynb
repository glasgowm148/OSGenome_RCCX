{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Genomic Cloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, gzip, glob, string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shutil import copyfile\n",
    "from subprocess import call\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "from geopy.geocoders import ArcGIS\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib\n",
    "matplotlib.use('Agg') # Stop matplotlib from opening a display window when generating images\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from matplotlib.pyplot import cm\n",
    "from matplotlib import rcParams\n",
    "from adjustText import adjust_text\n",
    "rcParams.update({'figure.autolayout': True}) # Auto-resize plot\n",
    "\n",
    "''' Main function for importing the input files, calling the ancestry c++ code, preprocessing the data, and calling the functions that create our images '''\n",
    "def prepare_data():\n",
    "\tfiles = list(['/data/23andme_MG_v4.txt','/refpanel_public_ref.gz','/gwas_ref.tsv','/23andme.txt.gz'])\n",
    "\t[copyfile(sys.argv[index+1], files[index]) for index in range(len(sys.argv)-1)]\n",
    "\twith open(files[0], 'rb') as f_in, gzip.GzipFile(files[3], 'wb') as gzip_file:\n",
    "\t\tgzip_file.write(f_in.read())\n",
    "\tcall([\"/home/ancestry_mirror/src/ancestry\", \"-i\", files[1], \"-b\", \"2\", \"-ranN\", \"100000\", \"-g23\", files[3], \"-o\", \"/home/ancestry_mirror/test\"])\n",
    "\tref = pd.read_csv(files[2], sep='\\t', index_col = [0]).rename(index=str, columns={'MAPPED_TRAIT':'trait'})\n",
    "\tref = ref[pd.to_numeric(ref['P-VALUE'], errors='coerce').notnull()]\n",
    "\tref = ref[pd.to_numeric(ref['RISK ALLELE FREQUENCY'], errors='coerce').notnull()]\n",
    "\tref = ref.loc[(ref['P-VALUE'].astype(float) < 0.1) & (ref['RISK ALLELE FREQUENCY'].astype(float) < 0.25)][list(ref)]\n",
    "\tdata23 = pd.read_csv(files[0], sep='\\t', names = ['SNPS','chrom','pos','geno'],  skiprows = 20)\n",
    "\tref['trait'] = ref['trait'].map(lambda trait: ','.join(str(trait).split(', ')))\n",
    "\tref = ref.assign(rallele = [variant.split('-')[1] if '-' in variant else '?' for variant in ref['STRONGEST SNP-RISK ALLELE'].values])\n",
    "\tref = ref.assign(variant = [str(row['SNPS']) + ':' +str(row['rallele']) for index, row in ref.iterrows()])\n",
    "\tdata23 = data23.assign(variant1 = [str(row['SNPS']) + ':' + str(row['geno'])[0] for _, row in data23.iterrows()])\n",
    "\tdata23 = data23.assign(variant2 = [str(row['SNPS']) + ':' + (str(row['geno'])[1] if len(str(row['geno'])) > 1 else '') for _, row in data23.iterrows()])\n",
    "\tsame1 = ref.loc[ref['variant'].isin(data23['variant1']) | ref['variant'].isin(data23['variant2'])][list(ref)]\n",
    "\tsame2 = data23.loc[data23['variant1'].isin(ref['variant']) | data23['variant2'].isin(ref['variant'])][list(data23)]\n",
    "\tc_dict = {'X': 23, 'Y' : 24, 'MT':25}\n",
    "\tfilter_chrom = lambda c: float(c) if (type(c) != str or (type(c) == str and unicode(c, 'utf-8').isnumeric())) else c_dict[c]\n",
    "\tsame2['chrom'] = same2['chrom'].map(filter_chrom)\n",
    "\tchrom_and_pos = np.asarray([same2.loc[same2['SNPS'] == snp][['pos','chrom']].values.reshape((2,)) for snp in same1['SNPS']])\n",
    "\tclusters = KMeans(n_clusters=150).fit_predict(chrom_and_pos)\n",
    "\tsame1 = same1.assign(clusters = clusters)\n",
    "\ttraits_per_snp = same1.drop_duplicates([\"clusters\", \"trait\"]).groupby('clusters')['trait'].apply(list)\n",
    "\tcreate_ancestry_image() # create the ancestry map\n",
    "\tcreate_wordcloud_image(same1) # create the word-cloud\n",
    "\tcreate_cluster_image(dict(Counter(same1['trait'].values)),traits_per_snp) # create the t-sne trait-association picture\n",
    "\n",
    "''' Function for creating your ancestry map.'''\n",
    "def create_ancestry_image(): \n",
    "\tanc_loc = {'ASHKENAZI': 'Poland', 'WEURASIA': 'Europe', 'BALOCHI-MAKRANI-BRAHUI': 'Pakistan', 'INDPAK': 'India', 'BANTUKENYA': 'Kenya', 'EAFRICA': 'Somalia', 'AFRICA': 'Africa', 'BANTUNIGERIA': 'Nigeria', 'WAFRICA': 'Ghana', 'BIAKA': 'Congo', 'CAFRICA': 'Chad', 'CAMBODIA-THAI': 'Cambodia', 'SEASIA': 'Phillipines', 'EASIA': 'Indonesia', 'CSAMERICA': 'Panama', 'AMERICAS': 'Nicaragua', 'CYPRUS-MALTA-SICILY': 'Sicily', 'EMED': 'Lebanon', 'SBALKANS': 'Serbia', 'ITALY': 'Itay', 'SWEUROPE': 'Sweden', 'EASTSIBERIA': 'Siberia', 'NEASIA': 'South Korea', 'FINNISH': 'Finland', 'NEEUROPE': 'England', 'GAMBIA': 'Gambia', 'GUJARAT': 'Gujarat', 'GUJARAT_PATEL': 'Gujarat', 'HADZA': 'Tanzania', 'HAZARA-UYGUR-UZBEK': 'Mongolia', 'CASIA': 'Kazakhstan', 'JAPAN-KOREA': 'Japan', 'KALASH': 'Pakistan', 'MENDE': 'Sierra Leone', 'NAFRICA': 'Tunisia', 'NCASIA': 'Kazakhstan', 'NEAREAST': 'Turkey', 'NEUROPE': 'Denmark', 'NGANASAN': 'Siberia', 'OCEANIA': 'Australia', 'PATHAN-SINDHI-BURUSHO': 'Pakistan', 'SAFRICA': 'South Africa', 'SAMERICA': 'Brazil', 'SARDINIA': 'Sardinia', 'SSASIA': 'Phillipines', 'BENGALI': 'India', 'TAIWAN': 'Taiwan', 'TUBALAR': 'Russia', 'TURK-IRAN-CAUCASUS': 'Iran'}\n",
    "\tanc_prop,anc_coord,anc_count = {}, {}, {}\n",
    "\tfor anc_prop_fn in glob.glob('/home/ancestry_mirror/test*.Q'):\n",
    "\t\twith open(anc_prop_fn,'r') as f_in:\n",
    "\t\t\tfor entry in f_in.readlines():\n",
    "\t\t\t\tanc_prop[entry.split(' ')[0]]  = anc_prop[entry.split(' ')[0]] + float(entry.split(' ')[1]) if entry.split(' ')[0] in anc_prop else float(entry.split(' ')[1])\n",
    "\t\t\t\tanc_count[entry.split(' ')[0]] = anc_count[entry.split(' ')[0]] + 1 if entry.split(' ')[0] in anc_count else 1\n",
    "\tarc_gis = ArcGIS(user_agent=\"ancestry_visualiser\",timeout=3)\n",
    "\tfor anc_group in anc_prop.keys():\n",
    "\t\tanc_prop[anc_group] /= anc_count[anc_group]\n",
    "\t\tanc_coord[anc_group] = arc_gis.geocode(anc_loc[anc_group]) if anc_prop[anc_group] > 0.01 else None\n",
    "\tmap = Basemap()\n",
    "\tmap.drawcoastlines()\n",
    "\tmap.drawmapboundary(fill_color='aqua')\n",
    "\tmap.fillcontinents(color='coral',lake_color='aqua')\n",
    "\tlongi, lati = map([loc.longitude if loc != None else -200 for loc in anc_coord.values()], [loc.latitude if loc != None else -200 for loc in anc_coord.values()])\n",
    "\ts = np.asarray([500*anc_prop[key] if anc_prop[key] != None else 0 for key in anc_coord.keys()])\n",
    "\tmap.scatter(longi, lati, s = s, marker='o',color='r')\n",
    "\tfor index,anc_group in enumerate(anc_coord.keys()):\n",
    "\t\trank = np.argsort(np.asarray(list(anc_prop.values())))[index]\n",
    "\t\tplt.text(longi[index],lati[index],str(rank+1),fontsize=12,fontweight='bold')\n",
    "\t\tplt.text(5, 200 + 15*rank, str(rank+1) + ') ' + anc_group + ' ' + str(anc_prop[anc_group]), fontsize=12,fontweight='bold')\n",
    "\tplt.savefig('./ancestry_map.png',bbox_inches=\"tight\", dpi=400)\n",
    "\n",
    "''' Function for creating a word cloud of your unique SNP traits '''\n",
    "def create_wordcloud_image(same1): \n",
    "\tplt.figure()\n",
    "\tfrequencies = Counter([item for sublist in same1[['SNPS','trait']].groupby('SNPS')['trait'].apply(list).values for item in sublist])\n",
    "\tplt.imshow(WordCloud(max_font_size=30).generate_from_frequencies(frequencies), interpolation=\"bilinear\")\n",
    "\tplt.axis(\"off\")\n",
    "\tplt.savefig('./wordcloud.png', dpi=400)\n",
    "\n",
    "''' Function for creating a cluster image of your traits '''\n",
    "def create_cluster_image(trait_dict,snp_traits):\n",
    "\ttop = [tup[0] for tup in Counter('#'.join(['#'.join(t) for t in snp_traits.values]).split('#')).most_common(20)]\n",
    "\tohe_traits = np.asarray([[1 if t in ts else 0 for t in trait_dict.keys()] for ts in snp_traits])\n",
    "\toccurrences = [np.nonzero(ohe_traits[:,list(trait_dict.keys()).index(trait)]) for trait in top]\n",
    "\ttsne_values = TSNE(n_components=2).fit_transform(ohe_traits)*5\n",
    "\tplt.figure()\n",
    "\ttxts = []\n",
    "\tc = [color for color in iter(cm.rainbow(np.linspace(0,1,20)))]\n",
    "\tfor indx in range(20):\n",
    "\t\txy = (tsne_values[occurrences[indx],0],tsne_values[occurrences[indx],1])\n",
    "\t\ttxts.append(plt.text(np.mean(xy[0]),np.mean(xy[1]), '\\n'.join(top[indx].split(' ')), fontsize=2, alpha=0.8, color=c[indx]))\n",
    "\t\tplt.scatter(xy[0], xy[1],marker=(2, 2, indx*360/(20*2)), s = 40, alpha=0.5, c=c[indx])\n",
    "\tadjust_text(txts)\n",
    "\tplt.axis(\"off\")\n",
    "\tplt.savefig('./clusters.png',dpi=400)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\tprepare_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
